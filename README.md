### **Modern Python Vectorization & Data Pipeline Benchmarks**

*Part of the 16-Week Edge AI Engineering Bootcamp*

---

## ğŸ¯ **Goal**

Understand and benchmark the performance differences between:

* **Pure Python loops**
* **NumPy** (C + SIMD)
* **Polars** (Rust + Apache Arrow + multithreading)
* **PyTorch** (tensor engine)

Tasks:

1. **Elementwise multiply** on arrays of size **N = 50,000,000**
2. **Realistic workload**: Group sensor readings by `sensor_id` and compute mean
   (5,000,000 rows, 1,000 sensor IDs)

This establishes why vectorized, columnar, and tensor-based operations are essential for **edge data pipelines**.

---
### Repo Structure

```bash
Week_02_Python-DataPipelines/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sensors/
â”‚   â”‚   â””â”€â”€ mpu6050.py          # Thin wrapper around MPU6050 driver
â”‚   â””â”€â”€ pipelines/
â”‚       â””â”€â”€ parquet_writer.py   # Chunked Parquet writer using Polars
â”œâ”€â”€ data/
â”‚   â””â”€â”€ parquet/                # Logged IMU chunks (Day 2)
â”œâ”€â”€ logger_v2.py                # 20 Hz streaming logger â†’ Parquet
â”œâ”€â”€ live_dashboard.py           # Basic Parquet-backed dashboard
â”œâ”€â”€ live_dashboard_pro.py       # Direct-streaming PRO demo (dark mode, 3D cube)
â””â”€â”€ README.md

---

# ğŸ§ª **A. Elementwise Multiply (N = 50,000,000)**

| Method        | Time (sec) | Speed-up vs Python |
| ------------- | ---------- | ------------------ |
| Python (loop) | **1.9672** | 1.0Ã—               |
| NumPy         | **0.1124** | 17.5Ã—              |
| Polars        | **0.1187** | 16.6Ã—              |
| PyTorch       | **0.0703** | 28.0Ã—              |

### ğŸ” **Interpretation**

* **Python loops** scale linearly and quickly saturate CPU.
* **NumPy** and **PyTorch** leverage **contiguous memory + SIMD**, making them drastically faster.
* **Polars**, although a DataFrame engine, catches up at large N (the DataFrame overhead becomes negligible).
* **PyTorch** is fastest because it uses highly optimized tensor kernels.

**Conclusion:**
For raw numeric transforms on large arrays, NumPy/Polars/PyTorch deliver **16â€“28Ã— speedups** over Python.

---

# ğŸ§ª **B. Realistic Task â€” GroupBy Mean (5,000,000 sensor readings)**

| Method                      | Time (sec) | Speed-up vs Python |
| --------------------------- | ---------- | ------------------ |
| Python groupby (dict-based) | **1.4242** | 1.0Ã—               |
| Polars groupby              | **0.1375** | 10.4Ã—              |

### ğŸ” **Interpretation**

* Pure Python requires manual dictionary accumulation â€” **slow, single-threaded**, no SIMD.
* **Polars** uses:

  * Rust
  * Apache Arrow columnar memory
  * Multithreading (Rayon)
  * SIMD vectorization
* It completes the same task **10.4Ã— faster**, even with only 1,000 group keys.

This is where Polars shines: realistic analytics workloads, not just toy elementwise ops.

---

# ğŸ§  **Why This Matters for Edge AI Pipelines**

Your workload in the Edge AI Bootcamp (and in your railway sensor projects) involves:

* Large, continuous sensor streams
* Timestamp alignment
* Grouping / averaging / window filters
* Multi-sensor joins
* Parquet I/O
* Post-processing for ML and quantized inference

These are EXACTLY the operations where Polars is engineered to win.

**This benchmark demonstrates:**

| Task Type                               | Best Tool       | Why                        |
| --------------------------------------- | --------------- | -------------------------- |
| pure math on huge arrays                | PyTorch / NumPy | optimal SIMD kernels       |
| dataframe analytics, groupby, windowing | Polars          | Rust engine, multithreaded |
| Python loops                            | âŒ never use     | no SIMD, slow              |

---

# ğŸ“ **Files in This Folder**

```
Week_02/
  Day_01/
    benchmarks.py     # Runs all benchmarks end-to-end
    README.md         # (this file)
```

---

# â–¶ï¸ **How to Run**

```
python benchmarks.py
```

Runs all tests:

* Elementwise vectorization benchmarks
* Realistic sensor-grouping benchmark

---

# ğŸ **Summary**

* Python loops: **too slow for edge workloads**
* NumPy: **strong baseline**, SIMD-enabled
* PyTorch: **fastest for raw tensor ops**
* Polars: **best for real multi-column analytics**, 10Ã— faster groupbys
* For your edge pipelines, Polars + PyTorch form the ideal foundation.

---

## Day 2 â€“ Real-Time Sensor Pipeline + Dashboards

**Goal:** Turn a simple IMU logger into a modern, efficient data pipeline with live visualization.

### What I Built

- **Streaming logger (`logger_v2.py`)**
  - Reads MPU6050 IMU over IÂ²C at **20 Hz**
  - Buffers samples in memory and writes **chunked Parquet** files (`data/parquet/`)
  - Uses **Polars** for fast DataFrame handling
  - Designed to keep RAM and CPU usage low on a Raspberry Pi 5

- **Student dashboard (`live_dashboard.py`)**
  - Reads latest Parquet chunk(s) with Polars
  - Dash + Plotly app with:
    - Live plot of `accel_x` (and optionally other axes)
    - Rolling window of recent samples
  - Updates every 0.5 s (Dash `Interval` callback)

- **Pro dashboard (`live_dashboard_pro.py`) â€“ demo only**
  - **No disk I/O**: talks directly to the MPU6050 in a background thread
  - Keeps a rolling **10 second ring buffer** in RAM (deque)
  - Dark-mode Dash UI with:
    - KPI cards:
      - RMS Accel (m/sÂ²)
      - Peak Gyro (Â°/s)
      - Temperature (Â°C)
      - Motion state: `STILL / MOVING / SHAKING`
    - 3 stacked time-series plots:
      - Acceleration (x, y, z)
      - Gyro (x, y, z)
      - Temperature
    - 3D **orientation cube** driven by accelerometer-based pitch/roll
  - Runs at ~5â€“10 FPS, fully interactive in the browser

### How to Run

#### 1. Logger + basic dashboard (student version)

```bash
# Terminal 1 â€“ logger
cd ~/EdgeAI_Bootcamp/Week_02_Python-DataPipelines
python logger_v2.py

# Terminal 2 â€“ basic dashboard
cd ~/EdgeAI_Bootcamp/Week_02_Python-DataPipelines
python live_dashboard.py

# If running Pro Dashboard there is not need to run logger but note that no parquet files are kept
# It's more of a showcase of what can be presented

cd ~/EdgeAI_Bootcamp/Week_02_Python-DataPipelines
python live_dashboard_pro.py

